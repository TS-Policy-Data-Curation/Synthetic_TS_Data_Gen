{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_numpy(file_path, delimiter=',', dtype=np.float32, skip_header=1, usecols=None):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a NumPy array, skipping headers and selecting specific columns.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        delimiter (str): Delimiter used in the CSV file. Default is ','.\n",
    "        dtype (data-type): Data type of the resulting array. Default is np.float32.\n",
    "        skip_header (int): Number of header rows to skip. Default is 1.\n",
    "        usecols (list or int): Columns to load. Default is None (load all columns).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: NumPy array containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a NumPy array, skipping headers and selecting specific columns\n",
    "    data = np.loadtxt(file_path, delimiter=delimiter, dtype=dtype, skiprows=skip_header, usecols=usecols)\n",
    "    return data\n",
    "\n",
    "def load_csv_to_tensor(file_path, delimiter=',', dtype=torch.float32, skip_header=1, usecols=None):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a PyTorch tensor, skipping headers and selecting specific columns.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        delimiter (str): Delimiter used in the CSV file. Default is ','.\n",
    "        dtype (torch.dtype): Data type of the resulting tensor. Default is torch.float32.\n",
    "        skip_header (int): Number of header rows to skip. Default is 1.\n",
    "        usecols (list or int): Columns to load. Default is None (load all columns).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: PyTorch tensor containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a NumPy array\n",
    "    data = load_csv_to_numpy(file_path, delimiter=delimiter, dtype=np.float32, skip_header=skip_header, usecols=usecols)\n",
    "    \n",
    "    # Convert the NumPy array to a PyTorch tensor\n",
    "    tensor = torch.tensor(data, dtype=dtype)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def load_csv_with_pandas(file_path, delimiter=','):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a pandas DataFrame for more flexible handling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        delimiter (str): Delimiter used in the CSV file. Default is ','.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path, delimiter=delimiter)\n",
    "\n",
    "def pandas_to_numpy(df, columns=None, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Convert specific columns of a pandas DataFrame to a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        columns (list or str): Columns to convert. Default is None (all numeric columns).\n",
    "        dtype (data-type): Data type of the resulting array. Default is np.float32.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: NumPy array containing the selected columns.\n",
    "    \"\"\"\n",
    "    if columns is not None:\n",
    "        df = df[columns]\n",
    "    return df.to_numpy(dtype=dtype)\n",
    "\n",
    "def pandas_to_tensor(df, columns=None, dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Convert specific columns of a pandas DataFrame to a PyTorch tensor.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        columns (list or str): Columns to convert. Default is None (all numeric columns).\n",
    "        dtype (torch.dtype): Data type of the resulting tensor. Default is torch.float32.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: PyTorch tensor containing the selected columns.\n",
    "    \"\"\"\n",
    "    if columns is not None:\n",
    "        df = df[columns]\n",
    "    return torch.tensor(df.to_numpy(), dtype=dtype)\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/home/vincentwork/Synthetic_TS_Data_Gen/data/Real_GDP.csv'\n",
    "\n",
    "# # Using pandas to load the CSV file\n",
    "# df = load_csv_with_pandas(file_path)\n",
    "\n",
    "# # Convert specific columns to NumPy arrays or PyTorch tensors\n",
    "# dates = df['observation_date'].values  # Convert dates to a NumPy array\n",
    "# gdp_values_numpy = pandas_to_numpy(df, columns=['GDPC1'])  # Convert GDP values to a NumPy array\n",
    "# gdp_values_tensor = pandas_to_tensor(df, columns=['GDPC1'])  # Convert GDP values to a PyTorch tensor\n",
    "\n",
    "# print(\"DataFrame:\")\n",
    "# print(df)\n",
    "\n",
    "# print(\"\\nDates (NumPy Array):\")\n",
    "# print(dates)\n",
    "\n",
    "# print(\"\\nGDP Values (NumPy Array):\")\n",
    "# print(gdp_values_numpy)\n",
    "\n",
    "# print(\"\\nGDP Values (PyTorch Tensor):\")\n",
    "# print(gdp_values_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: unemployment.csv\n",
      "Loading file: inflation.csv\n",
      "Loading file: Real_GDP.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through the data directory and load all the csv files\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "data_directory = '/home/vincentwork/Synthetic_TS_Data_Gen/data/'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file in os.listdir(data_directory):\n",
    "    if file.endswith(\".csv\"):\n",
    "        print(f\"Loading file: {file}\")\n",
    "        # Load the CSV file into a DataFrame\n",
    "        file_path = os.path.join(data_directory, file)\n",
    "        df = load_csv_with_pandas(file_path)\n",
    "        \n",
    "        # Convert the 'observation_date' column to datetime format\n",
    "        df['observation_date'] = pd.to_datetime(df['observation_date'])\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Merge all DataFrames on the 'observation_date' column\n",
    "merged_df = dataframes[0]  # Start with the first DataFrame\n",
    "\n",
    "for df in dataframes[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on='observation_date', how='outer')\n",
    "\n",
    "# Sort the merged DataFrame by 'observation_date'\n",
    "merged_df = merged_df.sort_values(by='observation_date')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "# print(merged_df.head())\n",
    "\n",
    "merged_df.drop(columns=['observation_date'], inplace=True)\n",
    "\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "merged_df.to_csv('/home/vincentwork/Synthetic_TS_Data_Gen/data/diffusion2.csv', index=False)\n",
    "\n",
    "# headers = merged_df.columns\n",
    "\n",
    "# # Convert to Numpy array\n",
    "# # Select only the columns containing the time series data\n",
    "# time_series_numpy = pandas_to_numpy(merged_df, columns=headers)\n",
    "# print(time_series_numpy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time_VAE_format: (1, 927, 3)\n",
      "[[[     nan      nan 2182.681]\n",
      "  [     nan      nan 2176.892]\n",
      "  [     nan      nan 2172.432]\n",
      "  ...\n",
      "  [   4.1        nan      nan]\n",
      "  [   4.1        nan      nan]\n",
      "  [   4.2        nan      nan]]]\n"
     ]
    }
   ],
   "source": [
    "### Convert to time_VAE formatting ###\n",
    "# time_VAE formatting: [samples, timestamps, features_list]\n",
    "# TODO: How do I get more samples? \n",
    "\n",
    "# Reshape the array into the format [samples, timestamps, features_list]\n",
    "# Since there is only 1 sample, we add an extra dimension at the beginning\n",
    "num_timestamps = time_series_numpy.shape[0]  # Number of timestamps\n",
    "num_features = time_series_numpy.shape[1]    # Number of features\n",
    "\n",
    "# Reshape to [1, timestamps, features]\n",
    "time_VAE_format = time_series_numpy.reshape(1, num_timestamps, num_features)\n",
    "\n",
    "# Print the shape of the resulting array\n",
    "print(\"Shape of time_VAE_format:\", time_VAE_format.shape)\n",
    "print(time_VAE_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data shape: (1000, 927, 3)\n"
     ]
    }
   ],
   "source": [
    "###Data Augmentation for more Samples###\n",
    "# Original time series data (1 sample, timestamps, features)\n",
    "original_data = time_VAE_format\n",
    "\n",
    "# Number of augmented samples to create\n",
    "num_augmented_samples = 1000\n",
    "\n",
    "# Initialize a list to store augmented samples\n",
    "augmented_data = []\n",
    "\n",
    "for _ in range(num_augmented_samples):\n",
    "    # Add random noise to the original data\n",
    "    noise = np.random.normal(0, 0.05, original_data.shape)  # Adjust noise level as needed\n",
    "    augmented_sample = original_data + noise\n",
    "    \n",
    "    # Append the augmented sample to the list\n",
    "    augmented_data.append(augmented_sample)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "augmented_data = np.concatenate(augmented_data, axis=0)\n",
    "\n",
    "print(\"Augmented data shape:\", augmented_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to /home/vincentwork/Synthetic_TS_Data_Gen/data/macroeconomic.npz\n"
     ]
    }
   ],
   "source": [
    "###Save the data to a .npz file###\n",
    "def save_numpy_to_npz(data, npz_file_path):\n",
    "    \"\"\"\n",
    "    Save a NumPy array directly into a compressed .npz file.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The NumPy array to save.\n",
    "        npz_file_path (str): Path to save the compressed .npz file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Save the NumPy array as a compressed .npz file\n",
    "    np.savez_compressed(npz_file_path, data=data)\n",
    "    \n",
    "    print(f\"Data successfully saved to {npz_file_path}\")\n",
    "\n",
    "data_directory = '/home/vincentwork/Synthetic_TS_Data_Gen/data/'\n",
    "npz_file_name = \"macroeconomic_diffusion.npz\"\n",
    "npz_file_path = os.path.join(data_directory, npz_file_name)\n",
    "\n",
    "save_numpy_to_npz(augmented_data, npz_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
